{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f494e021-727d-49fd-9be9-7caef053cd33",
   "metadata": {},
   "source": [
    "# Python Charmers \n",
    "\n",
    "## Mini Workshop 2: SQL and Python\n",
    "\n",
    "### Lesson Overview\n",
    "- **Objective:** We'll connect to Snowflake to read & write data, and execute queries.\n",
    "- **Source materials:** [The Information Lab NL](https://theinformationlab.nl/2022/09/23/connect-to-snowflake-from-python-script-sso/)\n",
    "- **Prerequisites:** [Lesson 3 Getting Started with Pandas](./fundamentals-03-getting-started-with-pandas.ipynb)\n",
    "- **Duration:** 30 mins\n",
    "\n",
    "One of the big limitations with SQL is the lack of functionality open source libraries and packages provide. With this tutorial we can have the best of both worlds, having data contained within a SQL database but with the functionality of Python too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414e78a-dfb4-4371-84cc-16a0f7d04fb5",
   "metadata": {},
   "source": [
    "## Python Libraries\n",
    "\n",
    "For these tasks we'll need 4 libraries installed:\n",
    "- snowflake.connector - for accessing snowflake\n",
    "- pandas - for creating dataframes\n",
    "- \"snowflake-connector-python[pandas]\" - for accessing more snowflake to pandas tools\n",
    "- json - to access data stored in a config file\n",
    "\n",
    "Please ensure you can run the script below, if not you will need to install the libraries as detailed in [Lesson 2 Packages](./fundamentals-02-packages.ipynb), and it recommended you close this file and start a new notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc85d81-4039-4c4e-8c8e-d49b1f9e6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector as sf\n",
    "import pandas as pd\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22017767-bb3d-4684-bafe-4cc9ad826de3",
   "metadata": {},
   "source": [
    "## Connecting to Snowflake\n",
    "\n",
    "We are logging on via Single Sign On in the browser.\n",
    "\n",
    "For this you will need:\n",
    "- **Account**: in your snowflake login url it is **account_identifier**.snowflakecomputing.com\n",
    "- **User**: your full email address, e.g. first.last@workplace.co.uk\n",
    "- **Authenticator**: this is 'externalbrowser'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6500a2-3ded-4b4f-a72d-b0226a1600c8",
   "metadata": {},
   "source": [
    "### 1. Set up Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5684a8e6-e20c-4106-a2e3-4eedb5c258c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO\n",
    "\n",
    "# Under python_charmers/data is a json file \"config_sql_workshop.json\"\n",
    "# Download this file and fill in your Username & Snowflake Account Identifier\n",
    "# Reupload this file and run the script below, you should see your username\n",
    "\n",
    "import json\n",
    "\n",
    "with open('../data/config_sql_workshop.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "user = config['user']\n",
    "account = config['account']\n",
    "\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb7178-a129-4357-a201-7e9e372e6095",
   "metadata": {},
   "source": [
    "### 2. Build Connection for Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b60e5-cc8e-4ec0-87b2-235c4869e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import snowflake.connector as sf\n",
    "import pandas as pd\n",
    "\n",
    "# Gets the version\n",
    "ctx = sf.connect(\n",
    "    account = account,\n",
    "    user=user,\n",
    "    authenticator= 'externalbrowser'\n",
    "    )\n",
    "\n",
    "# Create a cursor object.\n",
    "cur = ctx.cursor()\n",
    "\n",
    "# Execute a statement that will generate a result set.\n",
    "sql = \"SELECT current_version()\"\n",
    "cur.execute(sql)\n",
    "one_row = cur.fetchone()\n",
    "print(one_row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aeb190-fd36-4f8d-966d-4383ee2e88c3",
   "metadata": {},
   "source": [
    "## Read Data From Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e82a985-a8f7-4c60-bfac-6e2832cadad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TRANSACTION_CODE  VALUE  CUSTOMER_CODE  ONLINE_OR_IN_PERSON  \\\n",
      "0    DTB-716-679-576   1448         100001                    2   \n",
      "1     DS-976-542-770   7364         100009                    1   \n",
      "2     DS-551-937-380    475         100002                    1   \n",
      "3     DS-726-686-279   9455         100006                    2   \n",
      "4     DS-849-981-514   8500         100000                    2   \n",
      "..               ...    ...            ...                  ...   \n",
      "360  DSB-448-546-348   4525         100009                    1   \n",
      "361  DSB-474-374-857   5375         100000                    2   \n",
      "362   DS-367-545-264   7957         100007                    2   \n",
      "363  DSB-807-592-406   5520         100005                    1   \n",
      "364   DS-795-814-303   7839         100001                    2   \n",
      "\n",
      "        TRANSACTION_DATE  \n",
      "0    20/03/2023 00:00:00  \n",
      "1    09/10/2023 00:00:00  \n",
      "2    11/10/2023 00:00:00  \n",
      "3    10/08/2023 00:00:00  \n",
      "4    29/10/2023 00:00:00  \n",
      "..                   ...  \n",
      "360  27/05/2023 00:00:00  \n",
      "361  26/08/2023 00:00:00  \n",
      "362  18/08/2023 00:00:00  \n",
      "363  14/07/2023 00:00:00  \n",
      "364  15/11/2023 00:00:00  \n",
      "\n",
      "[365 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Execute a statement that will generate a result set.\n",
    "sql = \"SELECT * FROM TIL_PLAYGROUND.PREPPIN_DATA_INPUTS.PD2023_WK01;\"\n",
    "cur.execute(sql)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
    "df = cur.fetch_pandas_all()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f537e868-d4ab-4d7e-9ba6-6ad6cb0de1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT \n",
      "SPLIT_PART(transaction_code,'-',1) as bank, \n",
      "SUM(value) as total_value \n",
      "FROM pd2023_wk01 \n",
      "GROUP BY SPLIT_PART(transaction_code,'-',1);\n",
      "\n",
      "  BANK  TOTAL_VALUE\n",
      "0  DTB       618238\n",
      "1   DS       653940\n",
      "2  DSB       530489\n"
     ]
    }
   ],
   "source": [
    "# It doesn't have to be just SELECT *, you can run any SQL code\n",
    "# However for big code blocks include wrap the code in triple single quotes (''') \n",
    "# this will allow the full string to be captured\n",
    "# Alternatively you may want to read in a SQL script - more on that later\n",
    "\n",
    "# set database and schema path\n",
    "sql = \"USE TIL_PLAYGROUND.PREPPIN_DATA_INPUTS;\"\n",
    "cur.execute(sql)\n",
    "\n",
    "# query table in schema \n",
    "sql = '''\n",
    "SELECT \n",
    "SPLIT_PART(transaction_code,'-',1) as bank, \n",
    "SUM(value) as total_value \n",
    "FROM pd2023_wk01 \n",
    "GROUP BY SPLIT_PART(transaction_code,'-',1);\n",
    "'''\n",
    "print(sql)\n",
    "\n",
    "# Execute SQL script\n",
    "cur.execute(sql)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
    "df = cur.fetch_pandas_all()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5fe14-50de-4bb7-898d-eec71b0f1069",
   "metadata": {},
   "source": [
    "## Write Data To Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9933419-7bf5-4030-98d8-140029ddfc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1,\n",
       " 3,\n",
       " [('gsrlzfmsav/file0.txt', 'LOADED', 3, 3, 1, 0, None, None, None, None)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write data to Snowflake\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "write_pandas(conn=ctx,df=df,table_name='PY_TEST_PD2021_WK01',database='TIL_PLAYGROUND',schema='TEMP',auto_create_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee32585-37f0-440e-a541-731b60d7d2ec",
   "metadata": {},
   "source": [
    "## Read a SQL Script and Execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f2be2c-ea3f-42ea-8b53-927729af8424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM TIL_PLAYGROUND.PREPPIN_DATA_INPUTS.PD2021_WK01;\n",
      "    ORDER_ID CUSTOMER_AGE  BIKE_VALUE EXISTING_CUSTOMER        DATE  \\\n",
      "0          1           22         481                No  2021-04-25   \n",
      "1          2           28        1825                No  2021-01-23   \n",
      "2          3           51        1903                No  2021-07-03   \n",
      "3          4           59        1059                No  2021-01-24   \n",
      "4          5           44        1764               Yes  2021-08-12   \n",
      "..       ...          ...         ...               ...         ...   \n",
      "995      996           42        3460                No  2021-09-03   \n",
      "996      997           48        3409                No  2021-01-17   \n",
      "997      998           81        2534                No  2021-03-26   \n",
      "998      999           37        4312               Yes  2021-05-25   \n",
      "999     1000           35        1200               Yes  2021-02-18   \n",
      "\n",
      "            STORE_BIKE  \n",
      "0          York - Road  \n",
      "1          York - Road  \n",
      "2          York - Rood  \n",
      "3          York - Road  \n",
      "4      York - Mountain  \n",
      "..                 ...  \n",
      "995  London - Mountain  \n",
      "996  London - Mountain  \n",
      "997  London - Mountain  \n",
      "998    London - Gravel  \n",
      "999     Leeds - Graval  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Open and read the file as a single buffer\n",
    "fd = open('../data/example_sql_script.sql', 'r')\n",
    "sqlFile = fd.read()\n",
    "fd.close()\n",
    "\n",
    "print(sqlFile)\n",
    "\n",
    "cur.execute(sqlFile)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
    "df = cur.fetch_pandas_all()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33982a-4b22-4c69-8388-55a82b151e73",
   "metadata": {},
   "source": [
    "## Update and Create SQL Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3f3757-14aa-4bb5-a7f2-8cdfde87674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM TIL_PLAYGROUND.PREPPIN_DATA_INPUTS.PD2021_WK01;\n",
      "SELECT * FROM TIL_PLAYGROUND.PREPPIN_DATA_INPUTS.PD2022_WK01;\n"
     ]
    }
   ],
   "source": [
    "# Read Example SQL Script\n",
    "fd = open('../data/example_sql_script.sql', 'r')\n",
    "sqlFile = fd.read()\n",
    "fd.close()\n",
    "\n",
    "# Current SQL script\n",
    "print(sqlFile)\n",
    "\n",
    "# Change file contents and view\n",
    "sqlFile2 = sqlFile.replace('PD2021','PD2022')\n",
    "print(sqlFile2)\n",
    "\n",
    "# Create new SQL Script file\n",
    "f = open('../data/example_sql_script2.sql', \"w\")\n",
    "f.write(sqlFile2)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47daa6-b4fa-4e5b-a755-45ca7e40a7f7",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- ðŸ“° **Snowflake Docs** - Python Connector Pandas - https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-pandas\n",
    "- ðŸ“º **Dot PI** - Connect Python to Snowflake - https://www.youtube.com/watch?v=P560h6vZ4_Y\n",
    "- ðŸ“° **pyodbc library** - Connecting to SQL via ODBC connections - https://github.com/mkleehammer/pyodbc/wiki\n",
    "- ðŸ“º **Sigma Coding** - How to Use PYODBC With SQL Servers in Python - https://www.youtube.com/watch?v=eDXX5evRgQw\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this workshop we connected to Snowflake, read & wrote data to a database, and worked with reading and modifying SQL script files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
