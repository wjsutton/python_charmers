{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f494e021-727d-49fd-9be9-7caef053cd33",
   "metadata": {},
   "source": [
    "# Python Charmers \n",
    "\n",
    "## Mini Workshop 1: Hyper files\n",
    "\n",
    "### Lesson Overview\n",
    "- **Objective:** We'll explore building and working with hyper files using python.\n",
    "- **Source materials:** [Pantab's documentation](https://pantab.readthedocs.io/)\n",
    "- **Prerequisites:** [Lesson 3 Getting Started with Pandas](./fundamentals-03-getting-started-with-pandas.ipynb)\n",
    "- **Duration:** 45 mins\n",
    "\n",
    "Hyper files are design to store data extracted from various sources in a highly optimized way for quick aggregation, querying, and analysis in Tableau. The Hyper API that allows users and developers to create and interact with Hyper files programmatically, and we can do this simply with python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414e78a-dfb4-4371-84cc-16a0f7d04fb5",
   "metadata": {},
   "source": [
    "## Python Libraries\n",
    "\n",
    "For these tasks we'll need 3 libraries installed:\n",
    "- pandas - for working with dataframes\n",
    "- pantab - for converting dataframes to hyper extracts\n",
    "- tableauhyperapi - for accessing the full hyper API\n",
    "\n",
    "Please ensure you can run the script below, if not you will need to install the libraries as detailed in [Lesson 2 Packages](./fundamentals-02-packages.ipynb), and it recommended you close this file and start a new notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc85d81-4039-4c4e-8c8e-d49b1f9e6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "import tableauhyperapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22017767-bb3d-4684-bafe-4cc9ad826de3",
   "metadata": {},
   "source": [
    "## Writing to a Hyper Extract\n",
    "\n",
    "The below example will write out to a file named “example.hyper”, which Tableau can then report off of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1b3fde-6064-40cd-a5a5-efec45b43f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import pantab\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame([\n",
    "    [\"dog\", 4],\n",
    "    [\"cat\", 4],\n",
    "], columns=[\"animal\", \"num_of_legs\"])\n",
    "\n",
    "# convert dataframe to hyper file and save locally\n",
    "pantab.frame_to_hyper(df, \"example.hyper\", table=\"animals\")\n",
    "\n",
    "# Note as hyper files can support multiple data sources, table=\"animals\", is here to give a name to each added datasource\n",
    "# You'll see \"animals\" when you connect this file to Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aeb190-fd36-4f8d-966d-4383ee2e88c3",
   "metadata": {},
   "source": [
    "You'll notice we've generated a .log file, to prevent these happening with each process we can add a Hyper-Process to our pantab function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e82a985-a8f7-4c60-bfac-6e2832cadad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import pantab\n",
    "from tableauhyperapi import HyperProcess, Telemetry\n",
    "\n",
    "# set parameters for no logging and define hyper process\n",
    "parameters = {\"log_config\": \"\", \"default_database_version\": \"1\"}\n",
    "with HyperProcess(Telemetry.SEND_USAGE_DATA_TO_TABLEAU, parameters=parameters) as hyper:\n",
    "    \n",
    "    # create dataframe\n",
    "    df = pd.DataFrame([\n",
    "        [\"dog\", 4],\n",
    "        [\"cat\", 4],\n",
    "    ], columns=[\"animal\", \"num_of_legs\"])\n",
    "    \n",
    "    # convert dataframe to hyper file and save locally\n",
    "    pantab.frame_to_hyper(df, \"example.hyper\", table=\"animals\", hyper_process = hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99340f64-b50d-4604-9c69-81c6b1e4cfbf",
   "metadata": {},
   "source": [
    "## CSV file to Hyper\n",
    "\n",
    "Converting files to hyper is very quick with the **pantab** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c95274c-da21-4c92-a4dc-3c179890a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv('../data/2019_Yellow_Taxi_Trip_Data.csv')\n",
    "\n",
    "# convert dataframe to hyper file and save locally\n",
    "pantab.frame_to_hyper(df, \"taxi_trips.hyper\", table=\"taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215366d-9fab-4fb1-8fcc-c98ed515cf50",
   "metadata": {},
   "source": [
    "## Hyper file to CSV\n",
    "\n",
    "Similarly converting files from hyper is very quick with the **pantab** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f7d700-680e-4d53-ba4d-1bc327422213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "\n",
    "# read hyper file to dataframe\n",
    "df = pantab.frame_from_hyper(\"taxi_trips.hyper\", table=\"taxi\")\n",
    "\n",
    "# save dataframe \"df\" as csv\n",
    "df.to_csv('taxi_trips.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775eae6-4b80-4022-a544-76eabcdb6b8d",
   "metadata": {},
   "source": [
    "## Have a hyper file but don't know the contents?\n",
    "\n",
    "The script below will take a file and print the schemas, tables and columns. From [Community-Supported/list-hyper-contents](https://github.com/tableau/hyper-api-samples/tree/main/Community-Supported/list-hyper-contents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2d9dc8-c9fe-40be-a8a8-d036f5077d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 schemas:\n",
      " * Schema \"public\": 1 tables\n",
      "  -> Table \"taxi\": 18 columns\n",
      "    -> \"vendorid\" BIG_INT NOT NULL\n",
      "    -> \"tpep_pickup_datetime\" TEXT\n",
      "    -> \"tpep_dropoff_datetime\" TEXT\n",
      "    -> \"passenger_count\" BIG_INT NOT NULL\n",
      "    -> \"trip_distance\" DOUBLE\n",
      "    -> \"ratecodeid\" BIG_INT NOT NULL\n",
      "    -> \"store_and_fwd_flag\" TEXT\n",
      "    -> \"pulocationid\" BIG_INT NOT NULL\n",
      "    -> \"dolocationid\" BIG_INT NOT NULL\n",
      "    -> \"payment_type\" BIG_INT NOT NULL\n",
      "    -> \"fare_amount\" DOUBLE\n",
      "    -> \"extra\" DOUBLE\n",
      "    -> \"mta_tax\" DOUBLE\n",
      "    -> \"tip_amount\" DOUBLE\n",
      "    -> \"tolls_amount\" DOUBLE\n",
      "    -> \"improvement_surcharge\" DOUBLE\n",
      "    -> \"total_amount\" DOUBLE\n",
      "    -> \"congestion_surcharge\" DOUBLE\n"
     ]
    }
   ],
   "source": [
    "# Lists the schemas, tables, and columns inside a Hyper file\n",
    "from tableauhyperapi import HyperProcess, Telemetry, Connection, CreateMode, Nullability\n",
    "\n",
    "hyper_file = \"taxi_trips.hyper\"\n",
    "\n",
    "# Start Hyper and connect to our Hyper file\n",
    "with HyperProcess(telemetry=Telemetry.SEND_USAGE_DATA_TO_TABLEAU) as hyper:\n",
    "    with Connection(hyper.endpoint, hyper_file, CreateMode.NONE) as connection:\n",
    "        # The `connection.catalog` provides us with access to the meta-data we are interested in\n",
    "        catalog = connection.catalog\n",
    "\n",
    "        # Iterate over all schemas and print them\n",
    "        schemas = catalog.get_schema_names()\n",
    "        print(f\"{len(schemas)} schemas:\")\n",
    "        for schema_name in schemas:\n",
    "            # For each schema, iterate over all tables and print them\n",
    "            tables = catalog.get_table_names(schema=schema_name)\n",
    "            print(f\" * Schema {schema_name}: {len(tables)} tables\")\n",
    "            for table in tables:\n",
    "                # For each table, iterate over all columns and print them\n",
    "                table_definition = catalog.get_table_definition(name=table)\n",
    "                print(f\"  -> Table {table.name}: {len(table_definition.columns)} columns\")\n",
    "                for column in table_definition.columns:\n",
    "                    nullability = \" NOT NULL\" if column.nullability == Nullability.NOT_NULLABLE else \"\"\n",
    "                    collation = \" \" + column.collation if column.collation is not None else \"\"\n",
    "                    print(f\"    -> {column.name} {column.type}{nullability}{collation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400be32-99a8-40ff-bac0-73ce06b07ac7",
   "metadata": {},
   "source": [
    "## Reading and Writing Multiple Tables\n",
    "\n",
    "**frames_to_hyper** and **frames_from_hyper** can write and return a dictionary of DataFrames for Hyper extract, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee4aeaa-8158-4ae0-9808-5b81230060a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "from tableauhyperapi import TableName\n",
    "\n",
    "# dataframes to write to hyper\n",
    "taxi_df = pd.read_csv('../data/2019_Yellow_Taxi_Trip_Data.csv')\n",
    "hols_df = pd.read_csv('../data/holidays.csv')\n",
    "\n",
    "# define a dictionary (key pair) of dataframes\n",
    "dict_of_frames = {\n",
    "    \"taxis\": taxi_df,\n",
    "    \"holidays\": hols_df\n",
    "}\n",
    "\n",
    "pantab.frames_to_hyper(dict_of_frames, \"multi.hyper\")\n",
    "\n",
    "# Reading this hyper file will return a dictionary of dataframes\n",
    "result = pantab.frames_from_hyper(\"multi.hyper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19dce3-6aa6-47cd-a85e-52707269d2f6",
   "metadata": {},
   "source": [
    "## Appending Data to Existing Tables\n",
    "\n",
    "By default, **frame_to_hyper** and **frames_to_hyper** will fully drop and reloaded targeted tables. However, you can also append records to existing tables by supplying table_mode=\"a\" as a keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e616fb6-7b58-4910-9a7a-04fd00b83776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    [\"dog\", 4],\n",
    "    [\"cat\", 4],\n",
    "], columns=[\"animal\", \"num_of_legs\"])\n",
    "\n",
    "pantab.frame_to_hyper(df, \"animals.hyper\", table=\"animals\")\n",
    "\n",
    "new_data = pd.DataFrame([[\"moose\", 4]], columns=[\"animal\", \"num_of_legs\"])\n",
    "\n",
    "# Instead of overwriting the animals table, we can append via table_mode\n",
    "pantab.frame_to_hyper(df, \"animals.hyper\", table=\"animals\", table_mode=\"a\")\n",
    "\n",
    "# Please note that table_mode=\"a\" will create the table(s) if they do not already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e7b1b-1b4a-41b6-b0b0-98442547a42f",
   "metadata": {},
   "source": [
    "## Issuing SQL queries\n",
    "\n",
    "With **frame_from_hyper_query**, one can execute SQL queries against a Hyper file and retrieve the resulting data as a DataFrame. This can be used, e.g. to retrieve only a part of the data (using a WHERE clause) or to offload computations to Hyper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22481c22-c3da-4525-bf66-c81dcff03576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   passenger_count  trips  total_fares\n",
      "0                5    336      7227.88\n",
      "1                3    425      9945.16\n",
      "2                4    177      4579.05\n",
      "3                2   1475     35462.18\n",
      "4                6    203      4401.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pantab\n",
    "\n",
    "# create dataframe\n",
    "df = pd.read_csv('../data/2019_Yellow_Taxi_Trip_Data.csv')\n",
    "\n",
    "# convert dataframe to hyper file and save locally\n",
    "pantab.frame_to_hyper(df, \"taxi_trips.hyper\", table=\"taxi\")\n",
    "\n",
    "# Read a subset of the data from the Hyper file\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count, \n",
    "    COUNT(*) as trips,\n",
    "    SUM(total_amount) as total_fares\n",
    "FROM taxi\n",
    "WHERE passenger_count > 1\n",
    "GROUP BY passenger_count\n",
    "\"\"\"\n",
    "df = pantab.frame_from_hyper_query(\"taxi_trips.hyper\", query)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9af3a-e5e7-4a1c-a91f-a70cd4f29aec",
   "metadata": {},
   "source": [
    "## Publish a Hyper File\n",
    "\n",
    "To publish an extract we'll need to work with the **tableauserverclient** like we did at the end of [Lesson 8 Loops](./fundamentals-08-loops.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd80f3b-6341-4feb-954a-d1fbe0c133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tableauserverclient via terminal, if this package is not found\n",
    "import tableauserverclient as TSC\n",
    "\n",
    "# If you don't have a Tableau Cloud account you can sign up for free here: \n",
    "# Tableau Developer Programme: https://www.tableau.com/en-gb/developer\n",
    "\n",
    "# There are two ways to authenticate, which one you choose will depend on how you login to your Tableau Server:\n",
    "# - Username & Password\n",
    "# - Personal Access Token\n",
    "\n",
    "# However we do not want to share these details with the world, \n",
    "# so we will read these values from a local file, \"config\".\n",
    "# this means you can share this script without comprimising your access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cf389a-57b2-41e5-98b5-4162fb7f6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will.sutton\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO\n",
    "\n",
    "# Under python_charmers/data is a json file \"config_lesson_8.json\"\n",
    "# Download this file and fill in your login details, Username & Password or Personal Access Token\n",
    "# Reupload this file and run the script below, you should see either your username or PAT name below\n",
    "\n",
    "import json\n",
    "\n",
    "with open('../data/config_lesson_8.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "username = config['username']\n",
    "password = config['password']\n",
    "pat_name = config['pat_name']\n",
    "pat_secret = config['pat_secret']\n",
    "server_url = config['server_url']\n",
    "site_name = config['site_name']\n",
    "\n",
    "print(username)\n",
    "print(pat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7670ce-5081-4a83-a791-ec5f3a187823",
   "metadata": {},
   "source": [
    "### 1. Login with either Username & Password or Personal Access Token\n",
    "\n",
    "The other code block can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce91d9e-5bea-4914-9e34-6d4d79660003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login successful\n"
     ]
    }
   ],
   "source": [
    "# Username & Password - Tableau Auth\n",
    "tableau_auth = TSC.TableauAuth(username, password, site_name)\n",
    "server = TSC.Server(server_url, use_server_version=True)\n",
    "server.auth.sign_in(tableau_auth)\n",
    "print('login successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f421b-647e-497f-8611-df928162725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal Access Token - Tableau Auth\n",
    "tableau_auth = TSC.PersonalAccessTokenAuth(pat_name, pat_secret, site_name)\n",
    "server = TSC.Server(server_url, use_server_version=True)\n",
    "server.auth.sign_in(tableau_auth)\n",
    "print('login successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0fa06-0886-4455-bd2f-09999373febf",
   "metadata": {},
   "source": [
    "### 2. Find a project folder to store your extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cafa732-eec2-4faf-ba90-55705f5f2e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        project_name                     target_project_id\n",
      "0                            Default  224b0122-fad5-11e3-b3b7-273002f82ba8\n",
      "1                           Finances  224b0122-fad5-11e3-8c56-5bc312a8caf8\n",
      "2                          Marketing  224b283c-fad5-11e3-b609-2b4df1a13689\n",
      "3                 Monitoring Reports  7014fc06-522c-4a28-b32d-f0a313f53efb\n",
      "4                            Archive  c2798c6e-664e-4a47-986e-1638820ae9f3\n",
      "..                               ...                                   ...\n",
      "195                               JP  5ca4f2ba-5f55-454e-bb37-3a0599da1da5\n",
      "196                           Sorcha  98632413-0fc5-4b78-8fa0-3216b643b638\n",
      "197  External Assets Default Project  c461ef7e-11ec-462d-a1e1-52a5a482e1b6\n",
      "198                         Pat Test  452f3a3e-5af7-4be8-a576-487e9a5e8919\n",
      "199                  Pat Test Folder  0d0d5349-38e1-4b80-a8e0-83e39a8b1cbb\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with server.auth.sign_in(tableau_auth):\n",
    "    # Initialize lists to store project names and IDs\n",
    "    project_names = []\n",
    "    project_ids = []\n",
    "\n",
    "    # set limit to 1000\n",
    "    req_option = TSC.RequestOptions(pagesize=1000)\n",
    "    all_projects, pagination_item = server.projects.get(req_option)\n",
    "\n",
    "    for project in all_projects:\n",
    "        project_names.append(project.name)\n",
    "        project_ids.append(project.id)\n",
    "    \n",
    "proj_df = pd.DataFrame()\n",
    "proj_df['project_name'] = project_names\n",
    "proj_df['target_project_id'] = project_ids\n",
    "print(proj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d668b3bf-a14a-49fa-a759-72d71568583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    project_name                     target_project_id\n",
      "104  Will Sutton  2d4c61c7-8704-4128-b658-c767b01240b2\n"
     ]
    }
   ],
   "source": [
    "my_proj = proj_df[proj_df['project_name'].str.contains('Will')]\n",
    "\n",
    "print(my_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed227482-ee59-4845-84b8-0e0ca717a5e1",
   "metadata": {},
   "source": [
    "### 3. Submitting a request to publish your hyper file\n",
    "\n",
    "Using the project folder id, the hyper file path, and your tableau connection you can publish this extract to a Tableau Server/Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da7a4dd9-d972-4f27-b253-f285de93db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO \n",
    "# Enter your project folder id\n",
    "\n",
    "my_proj_id = ''\n",
    "hyper_filepath = '../data/taxi_trips.hyper'\n",
    "display_name = '2019 Taxi Trips'\n",
    "\n",
    "with server.auth.sign_in(tableau_auth):\n",
    "\n",
    "  # Use the project id to create new datsource_item\n",
    "  new_datasource = TSC.DatasourceItem(project_id = my_proj_id, name = display_name)\n",
    "\n",
    "  # publish data source (specified in file_path)\n",
    "  new_datasource = server.datasources.publish(new_datasource, hyper_filepath, 'CreateNew')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47daa6-b4fa-4e5b-a755-45ca7e40a7f7",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- 📰 **hyper-api-samples** - Tableau Hyper Samples - https://github.com/tableau/hyper-api-samples\n",
    "- 📺 **Tableau Dev Day 2023** - Hyper API Running in a Google Cloud Function | DataDev Day June 2023 - https://www.youtube.com/watch?v=j159gCmei8Q&list=PL_qx68DwhYA_5t8pl7r-GhAVBsT0ZvF4o&index=6\n",
    "- 📰 **tableau.github.io** - Tableau Server Client (Python) - https://tableau.github.io/server-client-python/docs/\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this workshop we created hyper files, modified the files, queried data within the hyper file, and lastly saw how we can publish these datasources to Tableau Server/Cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
